[["apis-and-iteration.html", "My Bookdown Chapter 1 APIs and Iteration 1.1 APIs 1.2 NPS Visitation Data 1.3 Functions 1.4 Functionize API Pulls 1.5 Function Defaults 1.6 Iterations 1.7 For loops 1.8 Mapping", " My Bookdown YOUR NAME 2023-03-01 Chapter 1 APIs and Iteration 1.0.1 Lesson Objectives In this lesson we will download data using an application programming interface (API), create our own functions, and iterate using for loops and map(). To fulfill these objectives we will be utilizing two park visitation data sets from the National Park Service (NPS): NPS-wide visitation data, and park unit-specific visitation data. There are seven exercises in this lesson that must be completed. 1.1 APIs An API is software that acts as an intermediary between an online data warehouse (or server) and its users (or clients). As data scientists, APIs provide us a way to request clean and nicely-formatted data that the server will then send to our local computers, all within our RStudio console! To work with APIs, we will need to use two new packages: httr, which allows us to communicate with the API‚Äôs server, and jsonlite, which allows us to work with one of the most common API data formats, JSON. Let‚Äôs go ahead and load in our packages for this lesson: library(tidyverse) library(httr) library(jsonlite) 1.2 NPS Visitation Data This week, we will be exploring NPS visitor use data across the NPS system as a whole, and and across specific park units. Like many institutions, NPS has a server that stores all of this information (as well as many other things), and an API for users to be able to access it. To utilize the NPS API in R, we first need to explore its API‚Äôs data structure. In almost every case, we use URLs to access specific data from APIs. To find the access URL for NPS visitation data, go to Stats Rest API - Documentation (though not very intuitive, the NPS API calls its visitation data set ‚ÄúStats‚Äù). Listed there you will see that all data associated with the ‚ÄúStats‚Äù data set can be accessed using the base URL https://irmaservices.nps.gov/v3/rest/stats. From there, you can tack on additional html text to access two different data sets: total/{year} and visitation. For starters, let‚Äôs try accessing the total/{year}. This data set gives us total monthly visitation across all NPS park units, for a user-selected year: https://irmaservices.nps.gov/v3/rest/stats/total/{YEAR} If you tried accessing that URL, you‚Äôll have noticed it doesn‚Äôt take you anywhere. This is because the curly brackets {} signify locations in the URL that need to be updated by the user based on their specific needs. I‚Äôm curious about visitor use in my birth year, so let‚Äôs tweak the URL to access visitation data from 1992. In R, we can access this data using httr‚Äôs GET() function, replacing {YEAR} with 1992. raw_data &lt;- httr::GET(url = &quot;https://irmaservices.nps.gov/v3/rest/stats/total/1992&quot;) # view raw_data # View(raw_data) Viewing the data set as-is, you can see it is not super human-readable. This is because data sent from APIs is typically packaged using JavaScript Object Notation (JSON). To unpack the data, we will first need to use httr‚Äôs content() function. In this example, we want the data to be extracted as text, since this is a data table. Moreover, its encoding is listed as UTF-8. The encoding parameter can be found by opening our raw data set in our R console: raw_data # lists &#39;UTF-8&#39; ## Response [https://irmaservices.nps.gov/v3/rest/stats/total/1992] ## Date: 2023-03-01 17:59 ## Status: 200 ## Content-Type: application/json; charset=utf-8 ## Size: 1.42 kB # convert content to text unpacked_data &lt;- httr::content(raw_data, as = &quot;text&quot;, encoding = &quot;UTF-8&quot;) Second, we need to transform this string of text, which is still in JSON formatting, into a data frame using jsonlite‚Äôs fromJSON(): # parse text from JSON to data frame final_data &lt;- jsonlite::fromJSON(unpacked_data) final_data ## Month NonRecreationVisitors RecreationVisitors UnitCode UnitName Year ## 1 1 6209285 10940618 NA NA 1992 ## 2 2 6010027 11931340 NA NA 1992 ## 3 3 6756902 15369139 NA NA 1992 ## 4 4 7255782 21458739 NA NA 1992 ## 5 5 7690763 26648530 NA NA 1992 ## 6 6 7593227 33284625 NA NA 1992 ## 7 7 8438755 41099305 NA NA 1992 ## 8 8 8056823 38625804 NA NA 1992 ## 9 9 7329755 26438266 NA NA 1992 ## 10 10 7105574 23616057 NA NA 1992 ## 11 11 6507805 14338165 NA NA 1992 ## 12 12 6702698 10943961 NA NA 1992 Hooray, you have now successfully pulled in an online data set using an API! üòÅ 1.2.1 Exercise #1 Using the code above as a starting point, pull in monthly NPS-wide visitation data for the years 1980, 1999, and 2018. ## accidentaly did way more advanced code for this part than was necessary at first! Please ignore, just for my future reference! # park.visitation &lt;- function(year = 2018){ # raw_data &lt;- httr::GET(url = paste0(&quot;https://irmaservices.nps.gov/v3/rest/stats/total/&quot;, year)) # unpacked_data &lt;- httr::content(raw_data, as = &quot;text&quot;, encoding = &quot;UTF-8&quot;) # final_data &lt;- jsonlite::fromJSON(unpacked_data) # return(final_data) # } # # years &lt;- c(1980, 1999, 2018) # # output.f.loop &lt;- vector(&quot;list&quot;, length = length(years)) # # for(i in 1:length(years)) { # output.f.loop[[i]] &lt;- park.visitation(year = years[i]) # } # # all_years &lt;- output.f.loop %&gt;% # bind_rows() data1980 &lt;- httr::GET(url = paste0(&quot;https://irmaservices.nps.gov/v3/rest/stats/total/&quot;, 1980)) unpacked1980 &lt;- httr::content(data1980, as = &quot;text&quot;, encoding = &quot;UTF-8&quot;) final1980 &lt;- jsonlite::fromJSON(unpacked1980) data1999 &lt;- httr::GET(url = paste0(&quot;https://irmaservices.nps.gov/v3/rest/stats/total/&quot;, 1999)) unpacked1999 &lt;- httr::content(data1999, as = &quot;text&quot;, encoding = &quot;UTF-8&quot;) final1999 &lt;- jsonlite::fromJSON(unpacked1999) data2018 &lt;- httr::GET(url = paste0(&quot;https://irmaservices.nps.gov/v3/rest/stats/total/&quot;, 2018)) unpacked2018 &lt;- httr::content(data2018, as = &quot;text&quot;, encoding = &quot;UTF-8&quot;) final2018 &lt;- jsonlite::fromJSON(unpacked2018) 1.2.2 Exercise #2 Now, let‚Äôs explore the second NPS visitation data set, visitation. This call pulls in monthly data for a specific park, across a specific time frame. Use your new API skills to pull in visitation data for Rocky Mountain National Park from 2010 through 2021, based on the API‚Äôs URL template. The unit code for Rocky Mountain National Park is ROMO. (Hint: an API URL can have multiple sections that need to be updated by the user.) ROMO.visitation &lt;- httr::GET(url = paste0(&quot;https://irmaservices.nps.gov/v3/rest/stats/visitation?unitCodes=ROMO&amp;startMonth=1&amp;startYear=2010&amp;endMonth=12&amp;endYear=2021&quot;)) ROMO.unpacked &lt;- httr::content(ROMO.visitation, as = &quot;text&quot;, encoding = &quot;UTF-8&quot;) ROMO.final &lt;- jsonlite::fromJSON(ROMO.unpacked) ##also accidentally did was more advanced code than necessary here! # startmonth &lt;- 1 # endmonth &lt;- 12 # startyear &lt;- 2010 # endyear &lt;- 2021 # sitecode &lt;- &quot;ROMO&quot; # # monthly.visitation &lt;- function(startyear = 2010){ # raw.months &lt;- httr::GET(url=paste0(&quot;https://irmaservices.nps.gov/v3/rest/stats/visitation?unitCodes=&quot;, sitecode, &quot;&amp;startMonth=&quot;, startmonth, &quot;&amp;startYear=&quot;, startyear, &quot;&amp;endMonth=&quot;, endmonth, &quot;&amp;endYear=&quot;, endyear)) # unpacked.months &lt;- httr::content(raw.months, as = &quot;text&quot;, encoding = &quot;UTF-8&quot;) # final.months &lt;- jsonlite::fromJSON(unpacked.months) # return(final.months) # } # # years.visitation = c(2010:2021) # # months.floop &lt;- vector(&quot;list&quot;, length = length(years.visitation)) # # for(i in 1:length(years.visitation)) { # months.floop[[i]] &lt;- monthly.visitation(year = years.visitation[i]) # } 1.3 Functions You may find yourself thinking, ‚ÄúWow, exercise 1 was overkill!‚Äù Indeed, you had to run several lines of code that were nearly identical to what was shown upstream; the only thing you needed to change from one year to the next was the year itself. This sort of redundant coding is not good coding practice. Instead of copying and pasting many coding steps over and over again and tweaking just a tiny portion of it, we can write functions that combine many coding steps into just one command. The benefits of reducing redundant code in this way are threefold. As Grolemund &amp; Wickham describe in their book, R for Data Science: It‚Äôs easier to see the intent of your code, because your eyes are drawn to what‚Äôs different, not what stays the same. It‚Äôs easier to respond to changes in requirements. As your needs change, you only need to make changes in one place, rather than remembering to change every place that you copied-and-pasted the code. You‚Äôre likely to have fewer bugs because each line of code is used in more places. Functions provide the option of changing just a minor part of the code base from one run to the next. Think of the GET() function in httr: it is a function that has code under-the-hood so that it isn‚Äôt necessary to write out the raw code each time we use it. Instead, we call out the function‚Äôs name (GET()), and the necessary argument within that function that tweaks the code to fit it to our needs (url = \"&lt;SOME_URL_WE_CHOOSE&gt;\"). 1.4 Functionize API Pulls Let‚Äôs try making a function called parkwide_visitation() that pulls in NPS-wide visitation data for a year of choice. To develop a function requires specific formatting: &lt;NAME&gt; &lt;- function(&lt;ARGUMENTS&gt;){ &lt;ACTIONS&gt; return(&lt;OUTPUT&gt;) } ‚Ä¶ where NAME is what we want to name the function; ARGUMENTS are the variables in the code that get ‚Äútweaked‚Äù; ACTIONS are the lines of code we want the function to perform (which includes our ARGUMENTS); and the OUTPUT is the object we want as the final outcome of running the function. For parkwide_visitation(), we will use our upstream code as the basis for our function, but with a few minor yet extremely important tweaks: parkwide_visitation &lt;- function(year){ # pull in the data raw_data &lt;- httr::GET(url = # parse out year so that it can be chosen with the &quot;year&quot; argument, using paste0() paste0(&quot;https://irmaservices.nps.gov/v3/rest/stats/total/&quot;, year)) # convert content to text extracted_data &lt;- httr::content(raw_data, as = &quot;text&quot;, encoding = &quot;UTF-8&quot;) # parse text from JSON to data frame final_data &lt;- jsonlite::fromJSON(extracted_data) return(final_data) } In the above function, our first object, raw_data, now changes based on how we define our year argument. We accomplish this through paste0(), which takes listed objects, transforms them into characters (if they aren‚Äôt already), and concatenates them into a single character string. For example: my_sentence &lt;- &quot;I need at least&quot; my_other_sentence &lt;- &quot;pints of ice cream a day&quot; paste0(my_sentence, &quot; &quot;, 08, &quot; &quot;, my_other_sentence, &quot;!&quot;) ## [1] &quot;I need at least 8 pints of ice cream a day!&quot; So, if we make year = 2021 in our parkwide_visitation() function, the year object becomes the number 2021, which makes the paste0() output ‚Äúhttps://irmaservices.nps.gov/v3/rest/stats/total/2021‚Äù, which subsequently pulls data for 2021. In other words, we can now pull visitation data for any year with just one line of code! pull_2018 &lt;- parkwide_visitation(year = 2018) pull_1980 &lt;- parkwide_visitation(year = 1980) pull_1992 &lt;- parkwide_visitation(year = 1992) # ... and so on! 1.4.1 Exercise #3 Create a function called unit_visitation() that pulls park-specific visitation data for any park, across any time frame. For a list of all park codes, download this spreadsheet. (Hint 1: functions can have multiple arguments. Hint 2: what‚Äôs the difference between 05 and \"05\"?) unit_visitation &lt;- function(parkcode, startmonth = &quot;01&quot;, startyear, endmonth = &quot;12&quot;, endyear){ raw.data &lt;- httr::GET(url = paste0(&quot;https://irmaservices.nps.gov/v3/rest/stats/visitation?unitCodes=&quot;, parkcode, &quot;&amp;startMonth=&quot;, startmonth, &quot;&amp;startYear=&quot;, startyear, &quot;&amp;endMonth=&quot;, endmonth, &quot;&amp;endYear=&quot;, endyear)) unpacked.data &lt;- httr::content(raw.data, as = &quot;text&quot;, encoding = &quot;UTF-8&quot;) final.data &lt;- jsonlite::fromJSON(unpacked.data) } 1.4.2 Exercise #4 Using unit_visitation(), pull in visitation data for Rocky Mountain National Park (ROMO), Everglades National Park (EVER), and Theodore Roosevelt National Park (THRO) from 1990 through 2021. pull.romo &lt;- unit_visitation(startyear = 1990, endyear = 2021, parkcode = &quot;ROMO&quot;) pull.ever &lt;- unit_visitation(startyear = 1990, endyear = 2021, parkcode = &quot;EVER&quot;) pull.thro &lt;- unit_visitation(startyear = 1990, endyear = 2021, parkcode = &quot;THRO&quot;) 1.5 Function Defaults Look at the code that you just wrote; writing out all of those unchanging date arguments still feels repetitive, right? When developing functions, there is an option for setting default values for arguments so that you don‚Äôt necessarily have to write all of them out every time you run it in the future. But, the option still exists within the function to make changes when necessary. For example, let‚Äôs tweak our parkwide_visitaion() function to have the default year be 2021: parkwide_visitation &lt;- function(year = &quot;2021&quot;) { raw_data &lt;- httr::GET(url = paste0(&quot;https://irmaservices.nps.gov/v3/rest/stats/total/&quot;, year)) # convert content to text extracted_data &lt;- httr::content(raw_data, as = &quot;text&quot;, encoding = &quot;UTF-8&quot;) # parse text from JSON to data frame final_data &lt;- jsonlite::fromJSON(extracted_data) return(final_data) } parkwide_visitation() ## Month NonRecreationVisitors RecreationVisitors UnitCode UnitName Year ## 1 1 11632614 11978413 NA NA 2021 ## 2 2 11082899 11692967 NA NA 2021 ## 3 3 12981524 18370611 NA NA 2021 ## 4 4 12857567 22155245 NA NA 2021 ## 5 5 13250575 27963739 NA NA 2021 ## 6 6 13789961 36122392 NA NA 2021 ## 7 7 14734920 41329530 NA NA 2021 ## 8 8 14280304 35380986 NA NA 2021 ## 9 9 13382939 30204635 NA NA 2021 ## 10 10 13882165 26961779 NA NA 2021 ## 11 11 13192146 18903397 NA NA 2021 ## 12 12 13007065 16051712 NA NA 2021 Because the default year is 2021, you don‚Äôt have to write it out explicitly in the function (so long as that‚Äôs the year you‚Äôre interested in). But, you still have the option of changing the year to something else: parkwide_visitation(year = &quot;1992&quot;) ## Month NonRecreationVisitors RecreationVisitors UnitCode UnitName Year ## 1 1 6209285 10940618 NA NA 1992 ## 2 2 6010027 11931340 NA NA 1992 ## 3 3 6756902 15369139 NA NA 1992 ## 4 4 7255782 21458739 NA NA 1992 ## 5 5 7690763 26648530 NA NA 1992 ## 6 6 7593227 33284625 NA NA 1992 ## 7 7 8438755 41099305 NA NA 1992 ## 8 8 8056823 38625804 NA NA 1992 ## 9 9 7329755 26438266 NA NA 1992 ## 10 10 7105574 23616057 NA NA 1992 ## 11 11 6507805 14338165 NA NA 1992 ## 12 12 6702698 10943961 NA NA 1992 1.5.1 Exercise #5 Default our unit_visitation() function‚Äôs arguments related to the starting and ending months to January and December, respectively. This way, we are automatically pulling in data for entire years. Rerun the function for ROMO, EVER, and THRO for the 1980-2021 time period to make sure it works properly. ## I had already created my function this way unit_visitation &lt;- function(parkcode, startmonth = &quot;01&quot;, startyear = 1980, endmonth = &quot;12&quot;, endyear = 2021){ raw.data &lt;- httr::GET(url = paste0(&quot;https://irmaservices.nps.gov/v3/rest/stats/visitation?unitCodes=&quot;, parkcode, &quot;&amp;startMonth=&quot;, startmonth, &quot;&amp;startYear=&quot;, startyear, &quot;&amp;endMonth=&quot;, endmonth, &quot;&amp;endYear=&quot;, endyear)) unpacked.data &lt;- httr::content(raw.data, as = &quot;text&quot;, encoding = &quot;UTF-8&quot;) final.data &lt;- jsonlite::fromJSON(unpacked.data) } pull.romo &lt;- unit_visitation(startyear = 1990, endyear = 2021, parkcode = &quot;ROMO&quot;) pull.ever &lt;- unit_visitation(startyear = 1990, endyear = 2021, parkcode = &quot;EVER&quot;) pull.thro &lt;- unit_visitation(startyear = 1990, endyear = 2021, parkcode = &quot;THRO&quot;) 1.6 Iterations At this point, we now know how to develop functions so that we do not have to keep writing out redundant steps in a workflow. However, in that last exercise, you can see that we are still writing out redundant code; we are performing the exact same function on each of our three park units. Another tool for reducing redundancy is iteration, which allows you to do the same thing on multiple inputs. Iteration can happen across different objects, different rows, different data frames, the list goes on and on! 1.7 For loops A for loop is base R‚Äôs iteration tool that executes code across a vector, an array, a list, etc. To save the outcome of each iteration, you must first create a vector to store the outputs in that is sized based on how many objects you want to iterate over. For example, I want to run our parkwide_visitation() function over the last five years: 2017, 2018, 2019, 2020, and 2021. To do that, I will first need to develop a vector listing each year: years &lt;- c(&#39;2017&#39;, &#39;2018&#39;, &#39;2019&#39;, &#39;2020&#39;, &#39;2021&#39;) ‚Ä¶ and then develop an empty list to store each year‚Äôs parkwide_visitation() results (i.e., output) into: output_floop &lt;- vector(&quot;list&quot;, length = length(years)) Now that we have a place to store each year‚Äôs function results, we can move forward with the for loop itself: for(i in 1:length(years)){ output_floop[[i]] &lt;- parkwide_visitation(year = years[i]) } ‚Ä¶ where years[i] tells the for loop to perform parkwide_visitation() on the ith year (think of i as a moving across each year), and output_floop[[i]] directs the for loop to store the results of the ith year‚Äôs run into output‚Äôs ith list (think of output_floop[[i]] as the location in output_floop that the ith‚Äôs results go). We now have a list containing five data frames: one for each year of visitation data: summary(output_floop) ## Length Class Mode ## [1,] 6 data.frame list ## [2,] 6 data.frame list ## [3,] 6 data.frame list ## [4,] 6 data.frame list ## [5,] 6 data.frame list Because each year‚Äôs output is structured identically, we can confidently combine each year‚Äôs data frame into a single data frame using dplyr::bind_rows(): multi_years &lt;- dplyr::bind_rows(output_floop) 1.7.1 Exercise #6 Use a for loop to run unit_visitation() with arguments start_year = 1980 and end_year = 2021 across ROMO, EVER, and THRO. Then, create a single data frame containing each park units‚Äô output. (Hint: Your first step will be to create a vector listing each park unit.) #also accidentally did was more advanced code than necessary here! # # unit_visitation &lt;- function(parkcode, startmonth = &quot;01&quot;, startyear = 1980, endmonth = &quot;12&quot;, endyear = 2021){ # raw.data &lt;- httr::GET(url = paste0(&quot;https://irmaservices.nps.gov/v3/rest/stats/visitation?unitCodes=&quot;, parkcode, &quot;&amp;startMonth=&quot;, startmonth, &quot;&amp;startYear=&quot;, startyear, &quot;&amp;endMonth=&quot;, endmonth, &quot;&amp;endYear=&quot;, endyear)) # unpacked.data &lt;- httr::content(raw.data, as = &quot;text&quot;, encoding = &quot;UTF-8&quot;) # final.data &lt;- jsonlite::fromJSON(unpacked.data) # return(final.data) # } parkcodes &lt;- c(&quot;ROMO&quot;, &quot;EVER&quot;, &quot;THRO&quot;) unit.parkcodes &lt;- vector(&quot;list&quot;, length = length(parkcodes)) for(i in 1:length(parkcodes)) { unit.parkcodes[[i]] &lt;- unit_visitation(parkcode = parkcodes[i]) } multi_parks &lt;- dplyr::bind_rows(unit.parkcodes) 1.8 Mapping The tidyverse‚Äôs purrr package has its own iteration function, map(), that is a variation of the for loop. map() takes a vector and applies a single function across it, then automatically stores all of the results into a list. In other words, map() creates an appropriately sized list to store our results in for us. This eliminates the need to create an empty list ahead of time. To create the same output as our previous for loop on parkwide_visitation(), but using map() instead, we would run the following code: output_map &lt;- years %&gt;% map(~ parkwide_visitation(year = .)) ‚Ä¶ where ~ indicates that we want to perform parkwide_visitation() across all years, and . indicates that we want to use our piped vector, years, as the input to the year argument. As you can see, output_map is identical to output_floop: identical(output_floop, output_map) ## [1] TRUE ‚Ä¶ which means we should also bind_rows() to get the mapped output into a single data frame: multi_years &lt;- bind_rows(output_map) 1.8.1 Exercise #7 Use map() to run unit_visitation() with arguments start_year = 1980 and end_year = 2021 across ROMO, EVER, and THRO. Then, create a single data frame containing each park units‚Äô output. park_map &lt;- parkcodes %&gt;% map(~ unit_visitation(parkcode = .)) multi_park_map &lt;- dplyr::bind_rows(park_map) # checking if they are identical identical(multi_park_map, multi_parks) ## [1] TRUE "],["data-munging.html", "Chapter 2 Data Munging 2.1 Pulling in necessary packages and data sets 2.2 Exploring our data 2.3 Pivoting 2.4 Joining", " Chapter 2 Data Munging 2.0.1 Lesson Objectives In the last lesson, we learned how to pull data from an API and reduce redundancies in our workflows through functions and iterations. In this lesson we will use the functions in the previous lesson to learn how to manipulate data frames with the tidyverse, and plot elegant time series graphs with the ggplot(), scales and plotly packages. There are five exercises in this lesson that must be completed. 2.1 Pulling in necessary packages and data sets library(tidyverse) library(httr) library(jsonlite) library(plotly) library(scales) Using the parkwide_visitation() function from the last lesson and mapping, let‚Äôs pull park-wide visitor data from 1980-2021, and name the final object parkwide. (Code hack: we can use 1980:2021 to create a vector of years so we don‚Äôt have to write each year out!) parkwide_visitation &lt;- function(year){ raw_data &lt;- httr::GET(url = paste0(&quot;https://irmaservices.nps.gov/v3/rest/stats/total/&quot;, year)) extracted_data &lt;- httr::content(raw_data, as = &quot;text&quot;, encoding = &quot;UTF-8&quot;) final_data &lt;- jsonlite::fromJSON(extracted_data) return(final_data) } years &lt;- (1980:2021) parkwide &lt;- years %&gt;% map(~ parkwide_visitation(year = .)) %&gt;% bind_rows() 2.1.1 Exercise #1 Using the unit_visitation() function from the last lesson and mapping, pull visitor data from 1980-2021 for the following park units: ROMO, ACAD, LAKE, YELL, GRCA, ZION, OLYM, and GRSM. Name the final output units. parkcodes2 &lt;- c(&quot;ROMO&quot;, &quot;ACAD&quot;, &quot;LAKE&quot;, &quot;YELL&quot;, &quot;GRCA&quot;, &quot;ZION&quot;, &quot;OLYM&quot;, &quot;GRSM&quot;) park_map_2 &lt;- parkcodes2 %&gt;% map(~ unit_visitation(parkcode = .)) units &lt;- dplyr::bind_rows(park_map_2) 2.2 Exploring our data Look at the data frame structure of parkwide and units; they‚Äôre exactly the same! So let‚Äôs go ahead and bind those together: visitation &lt;- bind_rows(parkwide, units) ‚Ä¶ except, the rows in parkwide‚Äôs UnitCode and UnitCode columns are empty. üòë Let‚Äôs fix the UnitCode column to list ‚ÄúParkwide‚Äù using mutate() and an ifelse() statement: visitation &lt;- visitation %&gt;% mutate(UnitCode = ifelse(is.na(UnitCode), &quot;Parkwide&quot;, UnitCode)) Think of the above ifelse() operation as: ‚ÄúIf the column UnitCode is NA, replace NA with Parkwide. Otherwise, preserve what is already in the UnitCode column.‚Äù Now that we have a single data set containing all of the NPS visitation data that we‚Äôve pulled, let‚Äôs start exploring it! But first, let‚Äôs aggregate the monthly data into annual data using group_by() and summarize(): yearly &lt;- visitation %&gt;% group_by(UnitCode, Year) %&gt;% # we only care about recreational visitors: summarize(RecVisitation = sum(RecreationVisitors)) yearly What does visitation data look like through time? First we can try to graph all of the park units together: ggplot(data=yearly)+ geom_point(aes(x = Year, y = RecVisitation, color = UnitCode)) + geom_path(aes(x = Year, y = RecVisitation, color = UnitCode)) + scale_y_continuous(labels = scales::label_scientific()) + theme_bw(base_size=10) ‚Ä¶ yikes, not surprisingly, parkwide visitation is wayyyy higher than our individual unit‚Äôs visitation data, making our graph pretty useless. It might be nice to have each park unit in a graph of its own. We can create individual graphs for each unit using facet_wrap(), and set the y-axes for each plot to \"free_y\": ggplot(data=yearly) + geom_point(aes(x = Year, y = RecVisitation, color = UnitCode)) + geom_path(aes(x = Year, y = RecVisitation, color = UnitCode)) + scale_y_continuous(labels = scales::label_scientific()) + facet_wrap(~UnitCode, scales = &quot;free_y&quot;) + theme_bw(base_size=10) We can also make this plot interactive by feeding it into plotly‚Äôs ggplotly() function: plotly::ggplotly( ggplot(data=yearly) + geom_point(aes(x = Year, y = RecVisitation, color = UnitCode)) + geom_path(aes(x = Year, y = RecVisitation, color = UnitCode)) + scale_y_continuous(labels = scales::label_scientific()) + facet_wrap(~UnitCode, scales = &quot;free_y&quot;) + theme_bw(base_size=10) ) 2.2.1 Exercise #2 Create an interactive graph with two separate panes: one showing park-wide visitation, the other showing all the individual park units together. Both panes should have different y-axes. library(dplyr) yearly &lt;- yearly %&gt;% mutate(Parkwide = if_else(UnitCode == &quot;Parkwide&quot;, &quot;Y&quot;, &quot;N&quot;)) plotly::ggplotly( ggplot(data = yearly) + geom_point(aes(x = Year, y = RecVisitation, color = UnitCode)) + geom_path(aes(x = Year, y = RecVisitation, color = UnitCode)) + scale_y_continuous(labels = scales::label_scientific()) + facet_wrap(~Parkwide, scales = &quot;free_y&quot;) + theme_bw(base_size = 10) ) It is pretty clear that some park units get orders of magnitude more visitors than others. But just how much of the total park visitation do each of these parks account for from year to year? Here we walk through two methods to tackle this question, pivoting and joining, to get park unit visitation side-by-side with park-wide data. 2.3 Pivoting Currently, our yearly data is considered narrow because we have all of our NPS visitation data in one column, with multiple rows representing the same year. We can make this data wide by using the function pivot_wider() wide_data &lt;- yearly %&gt;% select(Year, UnitCode, RecVisitation) %&gt;% pivot_wider(., names_from = UnitCode, values_from = RecVisitation) ‚Ä¶ where names_from represents the column with the values you are hoping to spread into new columns, and values_from represents the data you want to fill these new columns with. We can make the data set narrow again by using the function pivot_longer(): narrow_data &lt;- wide_data %&gt;% pivot_longer(cols = -Year, names_to = &quot;Park&quot;, values_to = &quot;RecVisitation&quot;) ‚Ä¶ where cols are the columns we want to gather into one column (or, the column(s) you DON‚ÄôT want to gather), while names_to and values_to are the names of the new columns produced from the pivot. 2.3.1 Exercise #3 Using wide_data as the starting point, create an interactive time series plot showing the annual percentage of the total visitation made up by all park units. #I used ChatGPT and a few help websitesto help with some of these functions parkwide_data &lt;- data.frame(id = wide_data$Parkwide) percent &lt;- (wide_data[,-1] /parkwide_data[,1]) * 100 percent &lt;- percent %&gt;% mutate(Years = 1980:2021) percent &lt;- percent[,-6] long_percent &lt;- percent %&gt;% pivot_longer(cols = -Years, names_to = &quot;Park&quot;, values_to = &quot;PercentVisitation&quot;) plotly::ggplotly( ggplot(data = long_percent)+ geom_point(aes(x = Years, y = PercentVisitation, color = Park)) + geom_path(aes(x = Years, y = PercentVisitation, color = Park)) + scale_y_continuous() + theme_bw(base_size = 10) ) 2.4 Joining Another way of getting park-wide visitation side-by-side with the park unit data is through the use of joining our original units and parkwide data sets: joined_data &lt;- inner_join(x = units, y = parkwide, by = c(&quot;Year&quot;,&quot;Month&quot;)) ‚Ä¶ where x and y are the two data sets you want joined, and by indicates the column(s) to match them by. Note: there are several ways of joining data. Explore them with ?`mutate-joins` and ?`filter-joins`. 2.4.1 Exercise #4 Using joined_data as the starting point, create an interactive time series plot showing the annual percentage of the total visitation made up by all park units. This plot should look nearly identical to the previous plot. joined_clean &lt;- joined_data %&gt;% group_by(Year, UnitCode.x) %&gt;% summarise(PercentVis = (sum(NonRecreationVisitors.x + RecreationVisitors.x)/ sum(NonRecreationVisitors.y + RecreationVisitors.y)) *100) joined_clean &lt;- joined_clean %&gt;% rename(UnitCode = UnitCode.x) plotly::ggplotly( ggplot(data = joined_clean) + geom_point(aes(x = Year, y = PercentVis, color = UnitCode)) + geom_path(aes(x = Year, y = PercentVis, color = UnitCode)) + scale_y_continuous()+ theme_bw(base_size = 10) ) 2.4.2 Exercise #5 Which park on average has the most visitation? Which park has the least visitation? Base your response on the data starting in 1990, ending in 2021. Defend your answer with numbers! average_df &lt;- joined_data %&gt;% group_by(UnitCode.x) %&gt;% summarise(Avg_Visitation = mean(sum(NonRecreationVisitors.x + RecreationVisitors.x))/32) ##The Great Smokey Mountains have the greatest visitation on average while Zion National Park has the least visitation on average "],["denouement.html", "Chapter 3 Denouement 3.1 Lesson Objectives: 3.2 Streaflow Datasets 3.3 Exercise #1 3.4 Exercise #2 3.5 Exercise #3 3.6 Exercise #4 3.7 Exercise #5", " Chapter 3 Denouement 3.1 Lesson Objectives: In this lesson you will take all of the skills you have learned up to this point and use them on a completely new set of data. This lesson has five exercises that need to be completed. 3.1.0.1 Necessary packages: library(tidyverse) library(plotly) library(scales) library(httr) library(jsonlite) library(dataRetrieval) library(sf) # for the map library(mapview) # for making the interactive plot library(dplyr) 3.2 Streaflow Datasets We are interested in looking at how the Cache la Poudre River‚Äôs flow changes as it travels out of the mountainous Poudre Canyon and through Fort Collins. There are four stream flow monitoring sites on the Poudre that we are interested in: two managed by the US Geological Survey (USGS), and two managed by the Colorado Division of Water Resources (CDWR): 3.2.1 USGS dataRetrieval R package To pull data for USGS stream gages, we can use the dataRetrieval package, which is a USGS-managed set of functions that, much like our functions from Lesson 3.1, pull data from the USGS‚Äôs data warehouse using an API. Here we will pull flow data for our USGS stream gages of interest for the last two water years: # pulls USGS daily (&#39;dv&#39;) stream flow data: usgs &lt;- dataRetrieval::readNWISdv(siteNumbers = c(&quot;06752260&quot;, &quot;06752280&quot;), # USGS site code for the Poudre River at the Lincoln Bridge and the ELC parameterCd = &quot;00060&quot;, # USGS code for stream flow startDate = &quot;2020-10-01&quot;, # YYYY-MM-DD formatting endDate = &quot;2022-09-30&quot;) %&gt;% # YYYY-MM-DD formatting rename(q_cfs = X_00060_00003) %&gt;% # USGS code for stream flow units in cubic feet per second (CFS) mutate(Date = lubridate::ymd(Date), # convert the Date column to &quot;Date&quot; formatting using the `lubridate` package Site = case_when(site_no == &quot;06752260&quot; ~ &quot;Lincoln&quot;, site_no == &quot;06752280&quot; ~ &quot;Boxelder&quot;)) 3.2.2 CDWR‚Äôs API Alas, CDWR does NOT have an R package that pulls data from their API, but they do have user-friendly directions on how to develop API calls. Using the ‚ÄúURL generator‚Äù steps outlined for their daily surface water time series data set, we can get the last two water years of CFS data for the Poudre at the Canyon mouth (site abbreviation = CLAFTCCO) using the following URL: https://dwr.state.co.us/Rest/GET/api/v2/surfacewater/surfacewatertsday/?format=json&amp;dateFormat=dateOnly&amp;fields=abbrev%2CmeasDate%2Cvalue%2CmeasUnit&amp;encoding=deflate&amp;abbrev=CLAFTCCO&amp;min-measDate=10%2F01%2F2020&amp;max-measDate=09%2F30%2F2022 3.3 Exercise #1 Using the URL above as the starting point, develop a function that creates a data frame of CDWR daily flow (CFS) data for a selected range of water years, for any site. (HINT: The final product of our API pull is a list with additional metadata about our API pull‚Ä¶ how do we index a list to extract the time series flow data?) getdailyCDWR &lt;- function(sitecode, startyear, endyear){ raw_CDWRdaily &lt;- httr::GET(url = paste0(&quot;https://dwr.state.co.us/Rest/GET/api/v2/surfacewater/surfacewatertsday/?format=json&amp;dateFormat=dateOnly&amp;fields=abbrev%2CmeasDate%2Cvalue%2CmeasUnit&amp;encoding=deflate&amp;abbrev=&quot;,sitecode,&quot;&amp;min-measDate=10%2F01%2F&quot;, startyear-1,&quot;&amp;max-measDate=09%2F30%2F&quot;, endyear)) unpacked_CDWRdaily &lt;- httr::content(raw_CDWRdaily, as = &quot;text&quot;, encoding = &quot;UTF-8&quot;) final_CDWRdaily &lt;- jsonlite::fromJSON(unpacked_CDWRdaily) return(final_CDWRdaily[[5]]) } 3.4 Exercise #2 Map over the function you developed in Exercise #1 to pull flow data for CLAFTCCO and CLARIVCO for the 2021 and 2022 water years. CLAFTCCO &lt;- getdailyCDWR(sitecode = &quot;CLAFTCCO&quot;, startyear = 2021, endyear = 2022) #For some reason there are only 687 observations in this data frame and I cannot figure out why there are missing values. This makes for some NAs later on in the assignment. CLARIVCO &lt;- getdailyCDWR(sitecode = &quot;CLARIVCO&quot;, startyear = 2021, endyear = 2022) 3.5 Exercise #3 Join our USGS and CDWR data frames together (bind_rows(), perhaps?), then create an interactive ggplot of discharge (in CFS) through time displaying all four of our monitoring sites. Be sure all axes and labels are clear. CLAFTCCO$numericDate &lt;- as.Date(CLAFTCCO$measDate, format = &quot;%Y-%m-%d&quot;) clean_claftcco &lt;- CLAFTCCO %&gt;% rename(site_no = abbrev, Date = numericDate, q_cfs = value) %&gt;% select(site_no, Date, q_cfs) CLARIVCO$numericDate &lt;- as.Date(CLARIVCO$measDate, format = &quot;%Y-%m-%d&quot;) clean_clarivco &lt;- CLARIVCO %&gt;% rename(site_no = abbrev, Date = numericDate, q_cfs = value) %&gt;% select(site_no, Date, q_cfs) clean_usgs &lt;- usgs %&gt;% select(site_no, Date, q_cfs) combined_data &lt;- bind_rows(clean_claftcco, clean_clarivco, clean_usgs) plotly::ggplotly( ggplot(data = combined_data) + geom_point(aes(x = Date, y = q_cfs, color = site_no))+ geom_path(aes(x = Date, y = q_cfs, color = site_no)) + scale_y_continuous()+ theme_bw(base_size = 10)+ labs(y = &quot;Discharge&quot;, title = &quot;Discharge over Poudre River Sites&quot;) ) 3.6 Exercise #4 Create an interactive plot of the daily difference in discharge between the Cache la Poudre River at the canyon mouth and each of the sites downstream. Make sure your plot axes are clear. wide_combined &lt;- combined_data %&gt;% pivot_wider(., names_from = site_no, values_from = q_cfs) wide_combined1 &lt;- wide_combined %&gt;% rename(ELC = &quot;06752280&quot;, Lincoln = &quot;06752260&quot;) wide_combined2 &lt;- wide_combined1 %&gt;% mutate(&quot;ELCdiff&quot; = CLAFTCCO - wide_combined$ELC, &quot;Lincolndiff&quot; = CLAFTCCO - wide_combined$Lincoln, &quot;CLARIVCOdiff&quot; = CLAFTCCO - wide_combined$CLARIVCO) diff_df &lt;- wide_combined2 %&gt;% select(Date, CLAFTCCO, ELCdiff, CLARIVCOdiff, Lincolndiff) diff_long &lt;- diff_df %&gt;% pivot_longer(cols = -Date, names_to = &quot;Site&quot;, values_to = &quot;Discharge&quot;) plotly::ggplotly( ggplot(data = diff_long) + geom_point(aes(x = Date, y = Discharge, color = Site))+ geom_path(aes(x = Date, y = Discharge, color = Site)) + scale_y_continuous()+ theme_bw(base_size = 10)+ labs(y = &quot;Discharge&quot;, title = &quot;Difference in Discharge over Poudre River Sites&quot;) ) 3.7 Exercise #5 For each of our downstream locations, calculate how many days the canyon mouth had LOWER flow. Is this what you expected? Why or why not? diff_df &lt;- diff_df %&gt;% mutate(ELCgreater = ifelse(ELCdiff &lt; 0, 1, 0,)) %&gt;% mutate(Lincolngreater = ifelse(Lincolndiff &lt; 0, 1, 0)) %&gt;% mutate(CLARIVCOgreater = ifelse(CLARIVCOdiff &lt; 0, 1, 0)) ELC &lt;- sum(diff_df$ELCgreater) Lincoln &lt;- sum(diff_df$Lincolngreater) CLARIVCOvalue &lt;- sum(diff_df$CLARIVCOgreater, na.rm = TRUE) There is lower flow in the canyon mouth 8 days at the ELC site, 38 (or more) days at the CLARIVCO site and 59 days at the Lincoln site. This does suprise me a little bit because I would expect that between the canyon mouth and the south east side of town, water is being removed from the river but water rights are very complex and different calls can be turned off and turned back on frequently and can vary the flow in the river dramatically. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
